{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for MNIST Data Set\n",
    "\n",
    "A logistic regression for the 0s and 1s only from the MNIST dataset.\n",
    "\n",
    "<img src=\"http://ufldl.stanford.edu/tutorial/images/Mnist_01.png\"/>\n",
    "\n",
    "Based on the [UFLDL tutorial](http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/) with a few key changes:\n",
    "\n",
    " - Matrix operations are used on the whole dataset (as a single batch given it is small), rather than loops on individual items.\n",
    " - Single training example x-values are row rather than column vectors (i.e. we use $y = x w^T + b$ not $y = w^T x + b$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch import tensor\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This time we'll use DataLoaders for their batching functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12665"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dataset from torchvision\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "train_dataset = datasets.MNIST(\"./data\", train=True,  download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Filter to those that are labelled as 0s or 1s\n",
    "train_images_list = [i[0].flatten() for i in train_dataset if i[1] < 2] \n",
    "train_values_list = [tensor(i[1]) for i in train_dataset if i[1] < 2]\n",
    "test_images_list = [i[0].flatten() for i in test_dataset if i[1] < 2] \n",
    "test_values_list = [tensor(i[1]) for i in test_dataset if i[1] < 2]\n",
    "len(train_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdb5ad22310>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.imshow(train_dataset[0][0].squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12665, 784]), torch.Size([12665, 1]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.stack(train_images_list)\n",
    "train_y = torch.stack(train_values_list).unsqueeze(1) # Make vertical tensor\n",
    "test_x = torch.stack(test_images_list)\n",
    "test_y = torch.stack(test_values_list).unsqueeze(1)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Logistic Function (Sigmoid)\n",
    "\n",
    "We now use sigmoid (`torch.sigmoid`) to constrain the predictions to a range of 0-to-1:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(y=1|x) &= h_\\theta(x) = \\frac{1}{1 + \\exp(-x \\theta^\\top)}\n",
    "\\\\\n",
    "P(y=0|x) &= 1 - P(y=1|x) = 1 - h_\\theta(x)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "### Loss\n",
    "\n",
    "For loss we will use negative log likelihood loss:\n",
    "\n",
    "$\n",
    "J(\\theta) = - \\sum_i \\left(y^{(i)} \\log( h_\\theta(x^{(i)}) ) + (1 - y^{(i)}) \\log( 1 - h_\\theta(x^{(i)}) ) \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943649291992"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nll_loss_binary(predictions: tensor, targets: tensor)-> float:\n",
    "    \"\"\"\n",
    "    Binary Negative Log Likelihood Loss (2 output classes)\n",
    "    \n",
    "    Rather than taking an batch size x categories tensor, it just\n",
    "    takes a batch size x 1 tensor as the prediction is simply either\n",
    "    1 or 0.\n",
    "    \"\"\"\n",
    "    left = targets * torch.log(predictions)\n",
    "    right = (1 - targets) * torch.log(1 - predictions)\n",
    "    negative_sum = - torch.sum(torch.stack([left, right]))\n",
    "    return negative_sum.item()\n",
    "\n",
    "# Test (expecting -ln(0.5*2) = 1.386)\n",
    "nll_loss_binary(tensor([[0.5,], [0.5]]), tensor([[1.,], [0.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(tensor([-100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "The gradient with respect to $\\theta$ comes out exactly as with linear regression:\n",
    "\n",
    "$\n",
    "\\nabla_\\theta J(\\theta) = \\sum_i x^{(i)} (h_\\theta(x^{(i)}) - y^{(i)})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 loss:  9448.189453125\n",
      "Epoch:  10 loss:  2822.199462890625\n",
      "Epoch:  20 loss:  1676.8770751953125\n",
      "Epoch:  30 loss:  1231.9415283203125\n",
      "Epoch:  40 loss:  991.583984375\n",
      "Epoch:  50 loss:  839.4447631835938\n",
      "Epoch:  60 loss:  733.7098388671875\n",
      "Epoch:  70 loss:  655.5446166992188\n",
      "Epoch:  80 loss:  595.1697998046875\n",
      "Epoch:  90 loss:  546.982666015625\n",
      "Epoch:  100 loss:  507.5332336425781\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(inputs: tensor, targets: tensor, epochs: int, learning_rate: float) -> tensor:\n",
    "    # Initialise random weights\n",
    "    weights = torch.rand(1, inputs.shape[1], dtype=torch.float) / inputs.shape[1]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Forward\n",
    "        activations = inputs @ weights.T\n",
    "        predictions = torch.sigmoid(activations)    \n",
    "        number_predictions = predictions.shape[0]\n",
    "        loss = nll_loss_binary(predictions, targets)\n",
    "        \n",
    "        # Backwards\n",
    "        errors = predictions - targets\n",
    "        gradients_weights = torch.matmul(errors.T, inputs) / number_predictions\n",
    "        \n",
    "        # Step\n",
    "        weights -= gradients_weights * learning_rate\n",
    "        \n",
    "        if i == 0 or ((i + 1) % 10) == 0:\n",
    "            print(\"Epoch: \", i + 1 , \"loss: \", loss)\n",
    "    \n",
    "    return weights\n",
    "    \n",
    "trained_weights = gradient_descent(train_x, train_y, 100, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Get accurancy, by calculating the number of correct predictions in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46335697174072266"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_accuracy(trained_weights: tensor, test_inputs: tensor, test_targets: tensor) -> float:\n",
    "    activations = test_inputs @ trained_weights.T\n",
    "    predictions = torch.sigmoid(activations)  \n",
    "    \n",
    "    # Get the predictions as most likely number (0 or 1), rather than probabilities\n",
    "    predicted_1 = predictions > 0.5\n",
    "    predicted_numbers = predicted_1.type(torch.int8)\n",
    "    \n",
    "    accurate_predictions = predicted_numbers == test_targets\n",
    "    accuracy = torch.sum(accurate_predictions) / test_targets.shape[0]\n",
    "    return accuracy.item()\n",
    "\n",
    "# Test with random numbers\n",
    "check_accuracy(torch.rand(1, test_x.shape[1], dtype=torch.float) / test_x.shape[1], test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976359605789185"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(trained_weights, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as expected (close to 100% accuracy as 0s and 1s are very different)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
