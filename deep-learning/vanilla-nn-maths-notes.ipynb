{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla NN - MNIST Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass\n",
    "\n",
    "For a single image:\n",
    "\n",
    "$x \\in \\mathbb{R}^{1 \\times n} = \\text{x-values as a row vector}\n",
    "\\\\\n",
    "n = \\text{number of x-values per item}$\n",
    "\n",
    "\n",
    "\n",
    "The second (hidden) layer activations are then calculated as follows:\n",
    "\n",
    "\n",
    "$z_2 = x w_1^T + b_1\n",
    "\\\\\n",
    "a_2 = \\text{ReLU}(z_2)\n",
    "\\\\\n",
    "w_1 \\in \\mathbb{R}^{m \\times n} = \\text{weights in layer 1}\n",
    "\\\\\n",
    "m = \\text{number of outputs in layer 2 per item}\n",
    "\\\\\n",
    "b_1 \\in \\mathbb{R} = \\text{single bias float in} L_1$\n",
    "\n",
    "Then for the third layer:\n",
    "\n",
    "$z_3 = a_2 w_2^T + b_2\n",
    "\\\\\n",
    "a_3 = f = \\text{ReLU}(z_3)\n",
    "\\\\\n",
    "k = \\text{correct category (of j categories)}\n",
    "\\\\\n",
    "\\displaystyle\n",
    "p_k = \\frac{e^{f_k}}{\\sum_j e^{f_j}}$\n",
    "\n",
    "Finally for negative log-likelihood loss:\n",
    "\n",
    "$L = -log(p_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards pass\n",
    "\n",
    "When calculating the partial derivatives backwards, we only care about how the weights impact the correct cateogry (k) for each item, as improving this will also reduce the propabilities on the incorrect categories.\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "\\frac{\\partial L}{\\partial p_k} = \\frac{-1}{p_k}\n",
    "$\n",
    "\n",
    "The using the quotient rule:\n",
    "\n",
    "$\n",
    "\\text{Let } \\sum = \\sum_j e^{f_j}, e = e^{f_k} \\text{ to simplify the notation}\n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "\\frac{\\partial p_k}{\\partial f_k} = \\frac{\\sum  De - e D\\sum}{\\sum^2} \n",
    "= \\frac{e(\\sum - e)}{\\sum^2}\n",
    "= \\frac{e}{\\sum} \\times \\frac{\\sum -e}{\\sum}\n",
    "= p_k \\times (1 - p_k)\n",
    "$\n",
    "\n",
    "Combining:\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "\\frac{\\partial L}{\\partial f_k} = \\frac{-p_k (1 - p_k)}{p_k} = p_k - 1\n",
    "$\n",
    "\n",
    "Going backwards:\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "\\frac{\\partial f_k}{\\partial f} = f \\bullet y\n",
    "\\\\\n",
    "y = \\text{one-hot-encoded vector of categories, with a 1 in the correct category for this item}\n",
    "\\\\\n",
    "\\displaystyle\n",
    "\\frac{\\partial f}{\\partial z_3} = z >= 1 \\text{then} 1 \\text{else} 0\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
