{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from matplotlib import pyplot\n",
    "from typing import Union, List\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Net From Scratch\n",
    "\n",
    "Creates a MLP using basic matrix manipulation only, in PyTorch. It does not use e.g. `nn.Linear`, `nn.ReLU` or `nn.Module`, and instead users lower level tensor operations (e.g. `matmul`).\n",
    "\n",
    "Most of the underlying equations are taken from the [Stanford Multi Layered Neural Networks tutorial](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "\n",
    "This model uses the [MNIST](https://pytorch.org/vision/stable/datasets.html#mnist) dataset of 32x32 grayscale images of hand-written digets. There are 60,000 training images and 10,000 test images (example image shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3785f79a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "train_dataset = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "pyplot.imshow(train_dataset[0][0].squeeze(), cmap='gray_r') # Squeeze to remove the color dimension (always 1 as grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not using `DataLoader` for the from-scratch work, so instead we'll just create on giant tensor for all the images and another for all the values. Datasets are just a list of x,y tuples, so this is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list = [i[0].flatten() for i in train_dataset]\n",
    "values_list = [i[1] for i in train_dataset]\n",
    "images = torch.stack(images_list)\n",
    "values_horizontal = torch.tensor(values_list)\n",
    "values = torch.unsqueeze(values_horizontal, 1)\n",
    "values\n",
    "images.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = 784, 64\n",
    "layer_2 = 64, 10\n",
    "\n",
    "def epoch(w1,w2,b1,b2):\n",
    "    # Forward pass\n",
    "    \n",
    "    # Layer 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-71a351bc55d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def create_batches(data: torch.dataset) -> List[torch.tensor]:\n",
    "    batches = []\n",
    "        \n",
    "    for (index, item) in enumerate(data):\n",
    "        batch_index = index // batch_size\n",
    "        batches[batch_index].append(item)\n",
    "        \n",
    "\n",
    "\n",
    "images = [i[0].flatten() for i in train_dataset]\n",
    "values = [i[1] for i in train_dataset]\n",
    "images[0].shape, values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function (Sigmoid)\n",
    "\n",
    "$\\displaystyle\n",
    "f(z) = \\frac{1}{1+\\exp(-z)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5dbd0a9ad4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msigmoid\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mEquivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "def sigmoid(input: tensor) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns a tensor with the sigmoid of the elements of input\n",
    "    \n",
    "    Equivalent to torch.nn.functional.sigmoid\n",
    "    \n",
    "    >>> sigmoid(tensor([1.,2]))\n",
    "    tensor([0.7311, 0.8808])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input: input tensor\n",
    "    \"\"\"\n",
    "    denominator = 1 + exp(-input)\n",
    "    return 1 / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Output\n",
    "\n",
    "<center><img src=\"http://ufldl.stanford.edu/tutorial/images/SingleNeuron.png\" width=\"400\"/></center>\n",
    "\n",
    "$\\displaystyle\n",
    "h_{W,b}(x) = f(W^Tx), x \\in \\mathbb{R}^{1 \\times n}, W \\in \\mathbb{R}^{m \\times n}$\n",
    "\n",
    "In the above example this is:\n",
    "\n",
    "$\\displaystyle\n",
    "h_{W,b}(x) = f(\\sum^3_{i=1} W_ix_i + b) = f(z)$ where $x \\in \\mathbb{R}^{1 \\times 3}, W \\in \\mathbb{R}^{1 \\times 3}$\n",
    "\n",
    "The weighted sum inputs ($z$) are calculated using the following function, and then sigmoid is applied to the result to get the activations $f(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum_inputs(inputs: tensor, weights: tensor, bias: float) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns the weighted sum of inputs, including the bias term.\n",
    "    \n",
    "    >>> # Single item, 2 inputs, 1 ouput\n",
    "    >>> i = tensor([1., 1]) # m = 2, n = 1\n",
    "    >>> w = tensor([1., 1]) # m = 2, n = 1\n",
    "    >>> weighted_sum_inputs(i,w,1)\n",
    "    tensor(3.)\n",
    "    \n",
    "    >>> # Single item, 2 inputs, 3 ouputs\n",
    "    >>> i = tensor([1., 1]) # m = 2, n = 1\n",
    "    >>> w = tensor([[1., 2, 3], [1, 1, 1]]) # m = 2, n = 3\n",
    "    >>> weighted_sum_inputs(i,w,1)\n",
    "    tensor([3., 4., 5.])\n",
    "    \n",
    "    >>> # Batch 3 items, 2 inputs, 1 ouput\n",
    "    >>> i = tensor([[1., 1, 1], [1, 1, 1]]) # m = 2, n = 3\n",
    "    >>> w = tensor([[1.], [1.]]) # m = 2, n = 1\n",
    "    >>> weighted_sum_inputs(i,w,1) # 3x1\n",
    "    tensor([[3., 3., 3.]])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs: \n",
    "        Row matrix for single item (1xm) with m = number of inputs. Matrix\n",
    "        (nxm) for a batch with n = batch size.\n",
    "    weights: \n",
    "        Row matrix for single output (1xm) with m = number of inputs. Matrix\n",
    "        (nxm) for multiple outputs (e.g. on a hidden layer here) with\n",
    "        n = number of outputs.\n",
    "    bias: bias term\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Matrix (nxm) of outputs where n = batch size and m = number of output\n",
    "        neurons.\n",
    "    \"\"\"\n",
    "    weights_transposed = transpose(weights, 0, -1)\n",
    "    return matmul(weights_transposed, inputs) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "\n",
    "<center><img src=\"http://ufldl.stanford.edu/tutorial/images/Network331.png\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propogation\n",
    "\n",
    "The model is defined as follows:\n",
    "\n",
    "$\n",
    "a^l = \\text{activation for layer } l\n",
    "\\\\\n",
    "W^{(l)} = \\text{weights for layer } l\n",
    "\\\\\n",
    "z^{(2)} = W^{(1)}x + b^{(1)}\n",
    "\\\\\n",
    "a^{(2)} = f(z^{(2)})\n",
    "\\\\\n",
    "z^{(3)} = W^{(2)} a^{(2)} + b^{(2)}\n",
    "\\\\\n",
    "h_{W,b}(x) = a^{(3)} = f(z^{(3)})$\n",
    "\n",
    "Note this will be implimented as part of the overall MLP rather than directly here, as we will need the component parts for backpropogation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "For a single training example, our loss is half squared-error (half to make the derivative easier):\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "J(W, b, x, y) = \\frac{1}{2}(h_{W,B}(x)-y)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_squared_error(activations: tensor, target_values: tensor) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns the half squared error, calculated elementwise\n",
    "    \n",
    "    >>> half_squared_error(tensor([1.,1]), tensor([1., 3]))\n",
    "    tensor([0., 2.])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    activations:\n",
    "        Matrix (nxm) of activations where n = batch size and m = number of \n",
    "        activations.\n",
    "    target_values:\n",
    "        Matrix (nxm) of target values (y-values) where n = batch size and\n",
    "        m = number of target values per single batch item.\n",
    "    \"\"\"\n",
    "    return 0.5 * ((activations - target_values) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a batch of size $m$, we can take the average cost (plus weight decay) as:\n",
    "\n",
    "$\\begin{align}\n",
    "C = J(W,b)\n",
    "&= \\left[ \\frac{1}{m} \\sum_{i=1}^m J(W,b;x^{(i)},y^{(i)}) \\right]\n",
    "                       + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l-1} \\; \\sum_{i=1}^{s_l} \\; \\sum_{j=1}^{s_{l+1}} \\left( W^{(l)}_{ji} \\right)^2\n",
    " \\\\\n",
    "&= \\left[ \\frac{1}{m} \\sum_{i=1}^m \\left( \\frac{1}{2} \\left\\| h_{W,b}(x^{(i)}) - y^{(i)} \\right\\|^2 \\right) \\right]\n",
    "                       + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l-1} \\; \\sum_{i=1}^{s_l} \\; \\sum_{j=1}^{s_{l+1}} \\left( W^{(l)}_{ji} \\right)^2\n",
    "\\end{align}$\n",
    "\n",
    "Weight decay is just the sum-of-squares of all weight values (in all layers and all dimensions), multiplied by a weight decay parameter $(\\lambda)$. It decreases the magnitude of the weights, to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(predictions: tensor, target_values: tensor, weights: List[tensor], weight_decay_parameter: float) -> float:\n",
    "    \"\"\"\n",
    "    Batch loss\n",
    "    \n",
    "    Returns the half mean squared error across a batch, plus a \n",
    "    weight decay term.\n",
    "    \n",
    "    >>> # Single batch item, single activation per item\n",
    "    >>> predictions = tensor([1.])\n",
    "    >>> target_values = tensor([3.])\n",
    "    >>> weights = [tensor([1.])]\n",
    "    >>> weight_decay_parameter = 0.\n",
    "    >>> batch_loss(predictions,target_values,weights,weight_decay_parameter)\n",
    "    2.0\n",
    "    \n",
    "    >>> # 3 batch items, single activation per item\n",
    "    >>> predictions = tensor([[1.],[2],[3]])\n",
    "    >>> target_values = tensor([[2.],[3],[4]])\n",
    "    >>> weights = [tensor([1])]\n",
    "    >>> weight_decay_parameter = 0.\n",
    "    >>> batch_loss(predictions,target_values,weights,weight_decay_parameter)\n",
    "    0.5\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions:\n",
    "        Matrix (nxm) of activations where n = batch size and m = number of \n",
    "        activations (i.e. a column vector for a batch with single outputs\n",
    "        per item).\n",
    "    target_values:\n",
    "        Matrix (nxm) of target values (y-values) where n = batch size and\n",
    "        m = number of target values per single batch item.\n",
    "    weights: \n",
    "        List of all weight tensors (for each layer) in the model. These\n",
    "        can be in any order as they are simply summed as part of the\n",
    "        weight decay calculations.\n",
    "    weight_decay_parameter: weight decay parameter (lambda)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the mean half squared error\n",
    "    half_squared_errors = half_squared_error(predictions, target_values)\n",
    "    count_predictions = numel(predictions)\n",
    "    mean_half_squared_error = torch.sum(half_squared_errors) / count_predictions\n",
    "    \n",
    "    # Calculate the weight decay\n",
    "    sum_weights = sum([torch.sum(w ** 2) for w in weights])\n",
    "    weight_decay = sum_weights * weight_decay_parameter / 2\n",
    "    \n",
    "    loss = mean_half_squared_error + weight_decay\n",
    "    return loss.item() # Cast single-element tensor as float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation\n",
    "\n",
    "#### Step function\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "W_{ij}^{(l)} &= W_{ij}^{(l)} - \\alpha \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b) \\\\\n",
    "b_{i}^{(l)} &= b_{i}^{(l)} - \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b)\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(weight_or_bias: Union[tensor, float], learning_rate: float, gradient: Union[tensor, float]) -> Union[tensor, float]:\n",
    "    \"\"\"\n",
    "    Returns an updated weight or bias tensor, stepped by the learning rate \n",
    "    multipled by the gradient vector.\n",
    "    \n",
    "    >>> # Step a bias\n",
    "    >>> step(1., 0.01, 1.)\n",
    "    0.99\n",
    "    \n",
    "    >>> # Step a weight\n",
    "    >>> weight = tensor([[1.,2],[3,4]])\n",
    "    >>> learning_rate = 0.01\n",
    "    >>> gradient = tensor([[2.,2],[2,2]])\n",
    "    >>> step(weight, learning_rate, gradient)\n",
    "    tensor([[0.9800, 1.9800],\n",
    "            [2.9800, 3.9800]])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weight_or_bias:\n",
    "        Weight tensor of size mxn where m = number of inputs and \n",
    "        n = number of outputs, or a bias float\n",
    "    learning_rate:\n",
    "        Learning rate (e.g. 0.01)\n",
    "    gradient: Gradient vector if stepping weights, of size mxn where\n",
    "    m = number of inputs and n = number of outputs, or a partial\n",
    "    derivative (float) if stepping the bias\n",
    "    \"\"\"\n",
    "    \n",
    "    return weight_or_bias - (learning_rate * gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "\n",
    "The derivative for the overall cost function is:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b) &=\n",
    "\\left[ \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \\right] + \\lambda W_{ij}^{(l)} \\\\\n",
    "\\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b) &=\n",
    "\\frac{1}{m}\\sum_{i=1}^m \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b; x^{(i)}, y^{(i)})\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "To caclulate the partial derivatives, we first calculate the error term $\\delta^{(l)}_i$ for each node $i$ in layer $l$.\n",
    "\n",
    "For the output unit in the output layer, this is:\n",
    "\n",
    "$\\begin{align}\n",
    "\\delta^{(n_l)}_i\n",
    "= \\frac{\\partial}{\\partial z^{(n_l)}_i} \\;\\;\n",
    "\\frac{1}{2} \\left\\|y - h_{W,b}(x)\\right\\|^2 = - (y_i - a^{(n_l)}_i) \\cdot f'(z^{(n_l)}_i)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "This gives error terms for the output layer as ($\\textstyle \\bullet$ denotes element-wise product):\n",
    "\n",
    "$\\begin{align} \\delta^{(n_l)} = - (y - a^{(n_l)}) \\bullet f'(z^{(n_l)}) \\end{align}$\n",
    "\n",
    "Note also that the derivative of sigmoid is:\n",
    "\n",
    "$f'(z) = f(z) (1-f(z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_terms_output_layer(predictions: tensor, target_values: tensor, predictions_before_activation: tensor) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns the error terms for the output layer\n",
    "    \n",
    "    >>> error_terms_output_layer(tensor([1.]), tensor([3.]), tensor([2.]))\n",
    "    tensor([4.])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions: predictions\n",
    "    target_values: target values (e.g. y-values)\n",
    "    predictions_before_activation: weights elementwise-multiplied by inputs plus bias\n",
    "    \"\"\"\n",
    "    activation_derivative = predictions_before_activation * (1 - predictions_before_activation)\n",
    "    \n",
    "    error_derivative = predictions - target_values\n",
    "    \n",
    "    return activation_derivative * error_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_terms_output_layer(tensor([[1.],[2]]), tensor([[3.],[4]]), tensor([[2.],[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error term for layer $l$ is calculated as follows:\n",
    "\n",
    "$\\delta^{(l)}_i = \\left( \\sum_{j=1}^{s_{l+1}} W^{(l)}_{ji} \\delta^{(l+1)}_j \\right) f'(z^{(l)}_i)$\n",
    "\n",
    "$\\begin{align} \\delta^{(l)} = \\left((W^{(l)})^T \\delta^{(l+1)}\\right) \\bullet f'(z^{(l)}) \\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_terms_hidden_layer(layer_weights: tensor, error_terms_next_layer: tensor, predictions_before_activation: tensor) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns the error terms for a hidden layer\n",
    "    \n",
    "    >>> error_terms_hidden_layer(tensor([[1.,1],[1,1]]), tensor([1.,1]), tensor([1.,1]))\n",
    "    tensor([0., 0.])\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    layer_weights: Weights used to caclulate this layers activations\n",
    "    error_terms_next_layer: Error terms from the next layer (e.g. from error_terms_output_layer if we are on layer l-1)\n",
    "    weighted_sum_inputs: weights elementwise-multiplied by inputs plus bias\n",
    "    \"\"\"\n",
    "    activation_derivative = predictions_before_activation * (1 - predictions_before_activation)\n",
    "    \n",
    "    layer_weights_transposed = transpose(layer_weights, 0, -1)\n",
    "    error_derivative = matmul(layer_weights_transposed, error_terms_next_layer)\n",
    "    \n",
    "    return activation_derivative * error_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can therefore comput the desired gradients:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\nabla_{W^{(l)}} J(W,b;x,y) &= \\delta^{(l+1)} (a^{(l)})^T, \\\\\n",
    "\\nabla_{b^{(l)}} J(W,b;x,y) &= \\delta^{(l+1)}.\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_gradient(error_terms_next_layer: tensor, layer_activations: tensor) -> tensor:\n",
    "    \"\"\"\n",
    "    Returns the gradient of the weights for a specific layer\n",
    "    \"\"\"\n",
    "    layer_activations_transposed = transpose(layer_activations, 0, -1)\n",
    "    return matmul(error_terms_next_layer, layer_activations_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Finally we create the full gradient descent algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x_batch: tensor, y_batch: tensor, epochs: int):\n",
    "    # Initialise random weight and bias values\n",
    "    weights_1 = rand(3,3)\n",
    "    weights_2 = rand(3)\n",
    "    bias_1 = 0.\n",
    "    bias_2 = 0.\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        \n",
    "        # Forward pass\n",
    "        z2 = weighted_sum_inputs(x_batch, weights_1, bias_1)\n",
    "        print(x_batch)\n",
    "        print(transpose(weights_1,0,-1))\n",
    "        print(bias_1)\n",
    "        print(z2)\n",
    "        \n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = weighted_sum_inputs(z2, weights_2, bias_2)\n",
    "        predictions = sigmoid(z3)\n",
    "\n",
    "        # Loss\n",
    "        loss = batch_loss(predictions, y_batch, [weights_1, weights_2], 0.01)\n",
    "        print(\"Epoch\", epoch, \" loss \", loss)\n",
    "\n",
    "        # Backpropogation\n",
    "        error_terms_layer_3 = error_terms_output_layer(predictions, y_batch, z3)\n",
    "        weight_2_gradient = weight_gradient(error_terms_layer_3, a2)\n",
    "        \n",
    "        # Step\n",
    "        weights_2 = step(weights_2, 0.01, weight_2_gradient)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(train_X, train_Y, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doctest.testmod(verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
